{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#### **Setup - Install Libraries and Import Dependencies**"
      ],
      "metadata": {
        "id": "wRlt0bDoKrcn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qqq transformers sentence-transformers faiss-cpu langchain ipywidgets langchain-community PyPDF2\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss # FAISS is used via LangChain's FAISS class\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "import warnings\n",
        "from google.colab import files # For file upload\n",
        "import PyPDF2\n",
        "\n",
        "# Suppress specific warnings that might clutter output\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module='transformers')\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"Libraries installed and dependencies imported.\")\n",
        "\n",
        "# --- Configuration Parameters ---\n",
        "# Define chunking parameters\n",
        "CHUNK_SIZE = 400  # Number of tokens/characters per chunk.\n",
        "CHUNK_OVERLAP = 40 # Overlap between chunks to maintain context.\n",
        "\n",
        "# Model names\n",
        "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
        "LLM_MODEL_NAME = 'TinyLlama/TinyLlama-1.1B-Chat-v1.0'\n",
        "\n",
        "# Placeholder for the uploaded document file name\n",
        "UPLOADED_FILE_NAME = None"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed and dependencies imported.\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--p3hXgBKrco",
        "outputId": "7a17e153-9891-430d-b9ea-6f3a5bd99f4d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Upload Your Assignment Document**"
      ],
      "metadata": {
        "id": "fQ_aQ11tKrco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "# Check if a file was uploaded\n",
        "if uploaded:\n",
        "    # Get the name of the first uploaded file\n",
        "    global UPLOADED_FILE_NAME\n",
        "    UPLOADED_FILE_NAME = list(uploaded.keys())[0]\n",
        "    print(f\"File '{UPLOADED_FILE_NAME}' uploaded successfully.\")\n",
        "else:\n",
        "    print(\"No file was uploaded. Please upload your document.\")"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9dae1bb6-d0e6-4155-89ed-e0422aed8d31\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9dae1bb6-d0e6-4155-89ed-e0422aed8d31\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 9241544228_eng.pdf to 9241544228_eng.pdf\n",
            "File '9241544228_eng.pdf' uploaded successfully.\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "hBytuUSmKrcp",
        "outputId": "dcf3e381-8ea6-4e53-a5ba-7756f2091ef4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Document Ingestion and Chunking**"
      ],
      "metadata": {
        "id": "Qtum5UyLKrcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if UPLOADED_FILE_NAME is None:\n",
        "    print(\"Error: No document file name found. Please run the upload cell first.\")\n",
        "else:\n",
        "    try:\n",
        "        if UPLOADED_FILE_NAME.lower().endswith('.pdf'):\n",
        "            text_content = \"\"\n",
        "            with open(UPLOADED_FILE_NAME, \"rb\") as f:\n",
        "                reader = PyPDF2.PdfReader(f)\n",
        "                for page_num in range(len(reader.pages)):\n",
        "                    text_content += reader.pages[page_num].extract_text()\n",
        "            print(f\"Content from '{UPLOADED_FILE_NAME}' loaded as PDF.\")\n",
        "        else:\n",
        "            with open(UPLOADED_FILE_NAME, \"r\", encoding=\"utf-8\") as f:\n",
        "                text_content = f.read()\n",
        "            print(f\"Content from '{UPLOADED_FILE_NAME}' loaded as text (UTF-8).\")\n",
        "\n",
        "\n",
        "        # Initialize the text splitter\n",
        "        text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size=CHUNK_SIZE,\n",
        "            chunk_overlap=CHUNK_OVERLAP,\n",
        "            length_function=len,\n",
        "            add_start_index=True\n",
        "        )\n",
        "\n",
        "        # Create document chunks\n",
        "        chunks = text_splitter.create_documents([text_content])\n",
        "\n",
        "        print(f\"Original document length: {len(text_content)} characters\")\n",
        "        print(f\"Number of chunks created: {len(chunks)}\")\n",
        "        print(f\"Example of first chunk content (first 150 chars):\\n'{chunks[0].page_content[:150]}...'\")\n",
        "        print(f\"Example of first chunk metadata: {chunks[0].metadata}\")\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File '{UPLOADED_FILE_NAME}' not found. Please ensure it was uploaded correctly.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during document ingestion: {e}\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Content from '9241544228_eng.pdf' loaded as PDF.\n",
            "Original document length: 658968 characters\n",
            "Number of chunks created: 1854\n",
            "Example of first chunk content (first 150 chars):\n",
            "'ThelCD-10\n",
            "Classification\n",
            "of Mental and\n",
            "Behavioural\n",
            "Disorders\n",
            "Clinical\n",
            "descriptions\n",
            "and diagnosticguidelines\n",
            "| World Health Organization\n",
            "I Geneva\n",
            "I 199...'\n",
            "Example of first chunk metadata: {'start_index': 0}\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_K1VPNyKrcp",
        "outputId": "4d446b7e-6b16-4431-e43c-d83db4a6f10c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Embedding and Vector Store**\n"
      ],
      "metadata": {
        "id": "JsRuJC4PKrcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'chunks' not in locals() or not chunks:\n",
        "    print(\"Error: No chunks found. Please ensure document ingestion was successful.\")\n",
        "else:\n",
        "    # Initialize the embedding model\n",
        "    print(f\"Loading embedding model: {EMBEDDING_MODEL_NAME}...\")\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
        "    print(\"Embedding model loaded.\")\n",
        "\n",
        "    # Create a FAISS vector store from the document chunks and embeddings\n",
        "    print(\"Creating FAISS vector store...\")\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    print(\"FAISS vector store created successfully.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading embedding model: all-MiniLM-L6-v2...\n",
            "Embedding model loaded.\n",
            "Creating FAISS vector store...\n",
            "FAISS vector store created successfully.\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dusvx5eyKrcp",
        "outputId": "113800d1-6fe1-42e8-f2d3-a6e7215b6873"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **LLM Integration - Load and Configure the Language Model**"
      ],
      "metadata": {
        "id": "zJ3iA66XKrcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the tokenizer for the chosen LLM\n",
        "print(f\"Loading tokenizer for LLM: {LLM_MODEL_NAME}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_NAME)\n",
        "print(\"Tokenizer loaded.\")\n",
        "\n",
        "# Load the LLM itself\n",
        "print(f\"Loading LLM: {LLM_MODEL_NAME}...\")\n",
        "try:\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        LLM_MODEL_NAME,\n",
        "        torch_dtype=torch.float16,\n",
        "        low_cpu_mem_usage=True,\n",
        "        trust_remote_code=True,\n",
        "    ).to(device)\n",
        "    print(\"LLM loaded successfully.\")\n",
        "\n",
        "    # Create a Hugging Face pipeline for text generation\n",
        "    pipe = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model,\n",
        "        tokenizer=tokenizer,\n",
        "        max_new_tokens=256,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.1,\n",
        "        return_full_text=False,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "\n",
        "    # Wrap the Hugging Face pipeline with LangChain's HuggingFacePipeline LLM\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "    print(\"LLM configured via HuggingFacePipeline for LangChain.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"ERROR: Could not load LLM '{LLM_MODEL_NAME}'. This might be due to insufficient VRAM or model compatibility issues.\")\n",
        "    print(f\"Please try a smaller model or ensure you have a GPU runtime. Error details: {e}\")\n",
        "    class DummyLLM:\n",
        "        def __call__(self, prompt, stop=None):\n",
        "            print(f\"Dummy LLM received prompt:\\n{prompt}\\n\")\n",
        "            return \"Dummy answer: LLM failed to load. Please check your LLM configuration.\"\n",
        "    llm = DummyLLM()\n",
        "    print(\"Using a Dummy LLM as a fallback. The QA system will not provide real answers.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Loading tokenizer for LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n",
            "Tokenizer loaded.\n",
            "Loading LLM: TinyLlama/TinyLlama-1.1B-Chat-v1.0...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM loaded successfully.\n",
            "LLM configured via HuggingFacePipeline for LangChain.\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UglbMYpyKrcq",
        "outputId": "9a0de30e-9791-485a-c912-2ecec7a373f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Query Interface and Retrieval-Augmented Generation (RAG) Chain**"
      ],
      "metadata": {
        "id": "cyw6ZTzoKrcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'vector_store' not in locals():\n",
        "    print(\"Error: Vector store not found. Please ensure embedding and vector store creation was successful.\")\n",
        "elif 'llm' not in locals():\n",
        "    print(\"Error: LLM not loaded. Please ensure LLM integration was successful.\")\n",
        "else:\n",
        "    # Configure the retriever\n",
        "    retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "    print(f\"Retriever configured to fetch top {retriever.search_kwargs['k']} chunks.\")\n",
        "\n",
        "    # Set up the RAG chain using LangChain's RetrievalQA\n",
        "    qa_chain = RetrievalQA.from_chain_type(\n",
        "        llm=llm,\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True\n",
        "    )\n",
        "    print(\"RAG chain (RetrievalQA) configured successfully.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever configured to fetch top 3 chunks.\n",
            "RAG chain (RetrievalQA) configured successfully.\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxofhy-eKrcq",
        "outputId": "200a3e50-9a41-4288-924d-da7ea5ca25c3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Output - Run Sample Query and Display Results**"
      ],
      "metadata": {
        "id": "uVFAJuKsKrcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if 'qa_chain' not in locals():\n",
        "    print(\"Error: QA chain not found. Please ensure the RAG chain was set up successfully.\")\n",
        "else:\n",
        "    # The specific test question provided in the assignment\n",
        "    test_question = \"Give me the correct coded classification for the following diagnosis: 'Recurrent depressive disorder, currently in remission'\"\n",
        "\n",
        "    print(f\"\\n--- Test Question ---\\n{test_question}\")\n",
        "\n",
        "    # Execute the RAG chain with the test question\n",
        "    response = qa_chain({\"query\": test_question})\n",
        "\n",
        "    # Display the generated answer\n",
        "    print(\"\\n--- Generated Answer ---\")\n",
        "    print(response[\"result\"])\n",
        "\n",
        "    # Display the source documents that were used by the LLM to generate the answer\n",
        "    print(\"\\n--- Source Documents (Context used by LLM) ---\")\n",
        "    if response[\"source_documents\"]:\n",
        "        for i, doc in enumerate(response[\"source_documents\"]):\n",
        "            print(f\"\\nChunk {i+1} (Source Index: {doc.metadata.get('start_index', 'N/A')}):\")\n",
        "            print(doc.page_content)\n",
        "    else:\n",
        "        print(\"No source documents were retrieved for this query.\")\n",
        "\n",
        "    print(\"\\n--- End of Sample Query ---\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Test Question ---\n",
            "Give me the correct coded classification for the following diagnosis: 'Recurrent depressive disorder, currently in remission'\n",
            "\n",
            "--- Generated Answer ---\n",
            " The code for this diagnosis would be F33.1\n",
            "\n",
            "--- Source Documents (Context used by LLM) ---\n",
            "\n",
            "Chunk 1 (Source Index: 361532):\n",
            "currently depressed (F31.3, F31.4 or F31.5), a recurrent depressive\n",
            "disorder  (F33.  -) or a depressive episode  (F32.  -). At  times,  however,\n",
            "the criteria for the diagnosis of another mental disorder cannot be\n",
            "met, although there is often some evidence of a psychopathologicalbasis for the complaint.\n",
            "Some patients will themselves make the connection between their\n",
            "\n",
            "Chunk 2 (Source Index: 128960):\n",
            "The following five-character codes might be used to specify the clinical\n",
            "disorder:\n",
            "F06.30 Organic manic disorder\n",
            "F06.31 Organic bipolar affective disorder\n",
            "63MENTAL AND BEHAVIOURAL DISORDERS\n",
            "F06.32 Organic depressive disorder\n",
            "F06.33 Organic mixed affective disorder\n",
            "F06.4 Organic anxiety disorder\n",
            "A disorder characterized by the essential descriptive features of a\n",
            "\n",
            "Chunk 3 (Source Index: 234362):\n",
            "recurrent depressive disorder (F33.-).\n",
            "These grades of severity are specified to cover a wide range of clinical\n",
            "states that are encountered in different types of psychiatric practice.\n",
            "Individuals with mild depressive episodes are common in primary\n",
            "care and general medical settings, whereas psychiatric inpatient units\n",
            "deal largely with patients suffering from the severe grades.\n",
            "\n",
            "--- End of Sample Query ---\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkjnkV7QKrcq",
        "outputId": "bda1b33f-b3ff-4c8d-819e-26ee8cd49f0a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Interactive Query Mode"
      ],
      "metadata": {
        "id": "RtN4v3YWgqkc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    user_query = input(\"\\nEnter your question (type 'exit' to quit): \")\n",
        "    if user_query.lower() == 'exit':\n",
        "        break\n",
        "    print(f\"\\n--- Your Question ---\\n{user_query}\")\n",
        "    user_response = qa_chain({\"query\": user_query})\n",
        "    print(\"\\n--- Generated Answer ---\")\n",
        "    print(user_response[\"result\"])\n",
        "    print(\"\\n--- Source Documents (Context used by LLM) ---\")\n",
        "    if user_response[\"source_documents\"]:\n",
        "        for i, doc in enumerate(user_response[\"source_documents\"]):\n",
        "            print(f\"\\nChunk {i+1}:\")\n",
        "            print(doc.page_content)\n",
        "    else:\n",
        "        print(\"No source documents were retrieved for this query.\")\n",
        "print(\"\\nInteractive query mode exited.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4Za8pJeWYQK",
        "outputId": "6fbe71ce-4873-42c8-d016-700ffb300bcb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Interactive Query Mode ---\n",
            "\n",
            "Enter your question (type 'exit' to quit): What is the purpose of the International Classification of Diseases?\n",
            "\n",
            "--- Your Question ---\n",
            "What is the purpose of the International Classification of Diseases?\n",
            "\n",
            "--- Generated Answer ---\n",
            " The purpose of the International Classification of Diseases (ICD) is to provide a standardized set of codes for medical diagnoses and billing procedures. It helps healthcare providers to communicate effectively with each other around the world and improves the efficiency of healthcare systems.\n",
            "\n",
            "--- Source Documents (Context used by LLM) ---\n",
            "\n",
            "Chunk 1:\n",
            "clearly stated ways, and thus to maximize the homogeneity ofstudy groups and the comparability of findings in multicentre and\n",
            "international studies.\n",
            "The book, which covers over 300 disorders, is derived from\n",
            "chapter V(F) of the Tenth Revision of the International Statistical\n",
            "Classification of Diseases and Related Health Problems (ICD-10).\n",
            "\n",
            "Chunk 2:\n",
            "in the Tenth Revision of\n",
            " the International Classification of Diseases and Related\n",
            "Health Problems (ICD-10) (9). Converting diagnostic criteria into diagnostic\n",
            "algorithms incorporated in the assessment instruments was useful in uncover-\n",
            "ing inconsistencies, ambiguities and overlap and allowing their removal. The\n",
            "work on refining the ICD-10 also helped to shape the assessment instruments.\n",
            "\n",
            "Chunk 3:\n",
            "several disorders that seem to appear almost exclusively in\n",
            "particular cultures. These disorders are described with the aim of\n",
            "stimulating the research needed to clarify their diagnostic\n",
            "relevance and allow their more precise classification.\n",
            "A list of the hundreds of experts involved in field trials of\n",
            "the research criteria, followed by a detailed index, concludes the\n",
            "book.\n",
            "\n",
            "Enter your question (type 'exit' to quit): How many people globally are estimated to have depression?\"\n",
            "\n",
            "--- Your Question ---\n",
            "How many people globally are estimated to have depression?\"\n",
            "\n",
            "--- Generated Answer ---\n",
            " The World Health Organization estimates that one out of every five people globally experience depression at least once in their lifetime. This means that approximately 600 million people worldwide are living with depression.\n",
            "\n",
            "--- Source Documents (Context used by LLM) ---\n",
            "\n",
            "Chunk 1:\n",
            "it is clear from the preliminary analysis of field trial data that in many centresthe category of \"mild depressive episode\" often had a comparatively low inter-rater reliability.\n",
            "It has also become evident that the views of clinicians on the required number\n",
            "of subdivisions of depression are strongly influenced by the types of patient\n",
            "\n",
            "Chunk 2:\n",
            "the clinicians involved in the field trials, and other comments received from\n",
            "a variety of sources, indicated a widespread demand for opportunities to specify\n",
            "several grades of depression and the other features noted above. In addition,\n",
            "\n",
            "Chunk 3:\n",
            "currently depressed (F31.3, F31.4 or F31.5), a recurrent depressive\n",
            "disorder  (F33.  -) or a depressive episode  (F32.  -). At  times,  however,\n",
            "the criteria for the diagnosis of another mental disorder cannot be\n",
            "met, although there is often some evidence of a psychopathologicalbasis for the complaint.\n",
            "Some patients will themselves make the connection between their\n",
            "\n",
            "Enter your question (type 'exit' to quit): Explain what ICD-10-CM is used for.\n",
            "\n",
            "--- Your Question ---\n",
            "Explain what ICD-10-CM is used for.\n",
            "\n",
            "--- Generated Answer ---\n",
            " ICD-10-CM is used to diagnose and code medical and surgical procedures, as well as other medical and non-medical services. It includes information on patient symptoms, examination findings, laboratory tests, imaging studies, and other diagnostic procedures. The code set covers a broad range of conditions and diseases, including physical and mental health problems, injuries, and chronic illnesses.\n",
            "\n",
            "--- Source Documents (Context used by LLM) ---\n",
            "\n",
            "Chunk 1:\n",
            "and service use.  Diagnostic  criteria for  research  has been produced for research\n",
            "purposes and is designed to be used in conjunction with this book. The much\n",
            "shorter glossary provided by Chapter V(F) for ICD-10 itself is suitable for\n",
            "use by coders or clerical workers, and also serves as a reference point for\n",
            "compatibility with other classifications; it is not recommended for use by mental\n",
            "\n",
            "Chunk 2:\n",
            "Regional Office for the Eastern Mediterranean, Alexandria, Egypt\n",
            "Dr Yang De-sen, Hunan Medical College, Changsha, Hunan, China\n",
            "XllIntroduction\n",
            "Chapter V, Mental and behavioural disorders, of ICD-10 is to be available\n",
            "in several different versions for different purposes. This version,  Clinical  descrip-\n",
            "tions and diagnostic  guidelines,  is intended for general clinical, educational\n",
            "\n",
            "Chunk 3:\n",
            "proportion of these categories has been left unused for the time being, so as\n",
            "to allow the introduction of changes into the classification without the need\n",
            "to redesign the entire system.\n",
            "ICD-10 as a whole is designed to be a central  (\"core\")  classification for a\n",
            "family of  disease-  and health-related classifications. Some members of  the family\n",
            "\n",
            "Enter your question (type 'exit' to quit): exit\n",
            "\n",
            "Interactive query mode exited.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}